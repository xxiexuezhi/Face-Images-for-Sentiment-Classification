{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as pyplot\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facial_raw_train = pd.read_csv(\"sentiment_data.csv\")\n",
    "face_lst=[]\n",
    "for i in range (len(facial_raw_train)):\n",
    "    face_lst.append(facial_raw_train[\"feature\"][i].split())\n",
    "images=np.asarray(face_lst,dtype=np.float32)\n",
    "img_lst=[]\n",
    "for j in range (len(images)):\n",
    "    img_lst.append(images[j].reshape(48,48))\n",
    "X_total=np.asarray(img_lst, dtype=np.float32)\n",
    "X_total=np.reshape(X_total, (len(X_total), 48, 48, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rotation_range=30)\n",
    "train_datagen.fit(X_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_lst=[]\n",
    "for i in range(len(facial_raw_train[\"label\"])):\n",
    "    Y_lst.append(facial_raw_train[\"label\"][i])\n",
    "    \n",
    "Y_total=np.asarray(Y_lst,dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data augmentation. some typical sample images from the processed dataset.\n",
    "for i in range(0, 9):\n",
    "    pyplot.subplot(330 + 1 + i)\n",
    "    pyplot.imshow(X_total[0:9][i].reshape(48, 48), cmap=pyplot.get_cmap('gray'))\n",
    "# show the plot\n",
    "pyplot.show()\n",
    "\n",
    "Y_total[0:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##data augmentation. some typical sample images from the raw dataset.\n",
    "\n",
    "\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(rotation_range=30)\n",
    "datagen.fit(X_total[0:9])\n",
    "for X_batch, y_batch in datagen.flow(X_total[0:9],Y_total[0:9], batch_size=9):\n",
    "\t# create a grid of 3x3 images\n",
    "\tfor i in range(0, 9):\n",
    "\t\tpyplot.subplot(330 + 1 + i)\n",
    "\t\tpyplot.imshow(X_batch[i].reshape(48, 48), cmap=pyplot.get_cmap('gray'))\n",
    "\t# show the plot\n",
    "\tpyplot.show()\n",
    "\tbreak\n",
    "print(X_batch.shape)\n",
    "y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(X_total,Y_total, test_ratio):\n",
    "    if (len(X_total)!=len(Y_total)):\n",
    "        return false\n",
    "    shuffled_indices = np.random.permutation(len(X_total))\n",
    "    test_set_size = int(len(X_total) * test_ratio)\n",
    "    test_indices = shuffled_indices[:test_set_size]\n",
    "    train_indices = shuffled_indices[test_set_size:]\n",
    "    return X_total[train_indices],Y_total[train_indices], X_total[test_indices],Y_total[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import to_categorical\n",
    "import cv2\n",
    "\n",
    "def pre_process(fileName,test_ratio):\n",
    "    \"\"\"\n",
    "    The function load provided CSV dataset and further reshape, rescale the data for feeding\n",
    "    \"\"\"\n",
    "    facial_raw_train = pd.read_csv(fileName)\n",
    "    face_lst=[]\n",
    "    for i in range (len(facial_raw_train)):\n",
    "        face_lst.append(facial_raw_train[\"feature\"][i].split())\n",
    "    images=np.asarray(face_lst,dtype=np.float32)\n",
    "    img_lst=[]\n",
    "    \n",
    "    \n",
    "    #Resizing the image (48 * 48) to (32 * 32) for decresing paramemeter when training models\n",
    "    for j in range (len(images)):\n",
    "        img=images[j].reshape(48,48)\n",
    "        img=cv2.resize(img,(32,32))\n",
    "        img_lst.append(img)\n",
    "        \n",
    "    X_total=np.asarray(img_lst, dtype=np.float32)\n",
    "    X_total=np.reshape(X_total, (len(X_total), 32, 32, 1))\n",
    "    \n",
    "    Y_lst=[]\n",
    "    for i in range(len(facial_raw_train[\"label\"])):\n",
    "        Y_lst.append(facial_raw_train[\"label\"][i])\n",
    "    \n",
    "    Y_total=np.asarray(Y_lst,dtype=np.float32)\n",
    "    Y_total = to_categorical (Y_total)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    print (X_total.shape)\n",
    "    \n",
    "    X_train,Y_train,X_test,Y_test = split_train_test(X_total,Y_total, test_ratio) \n",
    "    \n",
    "    \n",
    "   \n",
    "    train_datagen = ImageDataGenerator(rotation_range=30)\n",
    "    train_datagen.fit(X_train)\n",
    "    \n",
    "    test_datagen = ImageDataGenerator(rotation_range=30)\n",
    "    test_datagen.fit(X_test)\n",
    "    \n",
    "    \n",
    "    import pickle\n",
    "    fileObject=open(\"processed_data\",'wb')\n",
    "    pickle.dump((X_train,Y_train, X_test, Y_test, train_datagen, test_datagen), fileObject)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_process(\"sentiment_data.csv\",0.3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "fileObject=open(\"processed_data\",'rb')\n",
    "X_train,Y_train,X_test,Y_test, train_datagen, test_datagen = pickle.load(fileObject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_shape=(32,32,1)\n",
    "model= Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3,3),activation='relu',input_shape = input_shape, padding='same'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Conv2D(64,kernel_size=(3,3),activation='relu',padding='same'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "           \n",
    "           \n",
    "model.add(Conv2D(128,kernel_size=(3,3),activation='relu',padding='same'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(7,activation = 'softmax'))\n",
    "           \n",
    "model.summary()\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "model.compile(Adam(lr=.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(train_datagen.flow(X_train, Y_train, batch_size=256),\n",
    "                    steps_per_epoch=len(X_train) // 256,\n",
    "                    epochs=30,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate (X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, load_model\n",
    "from keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_model = VGG16(weights = 'imagenet', include_top = False)\n",
    "x = vgg16_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "predictions = Dense(7, activation = 'softmax')(x)\n",
    "vgg_model = Model(input = vgg16_model.input, output = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze all layers of the pre-trained model\n",
    "for layer in vgg16_model.layers:\n",
    "    layer.trainable = False\n",
    "vgg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "V_X_train = [cv2.cvtColor(cv2.resize(i, (32, 32)), cv2.COLOR_GRAY2RGB) for i in X_train]\n",
    "V_X_test=[cv2.cvtColor(cv2.resize(i, (32, 32)), cv2.COLOR_GRAY2RGB)\n",
    "           for i in X_test]\n",
    "V_X_train = np.concatenate([arr[np.newaxis] for arr in V_X_train]).astype('float32')\n",
    "V_X_test = np.concatenate([arr[np.newaxis] for arr in V_X_test]).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "vgg_model.compile(Adam(lr=.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model.fit_generator(train_datagen.flow(V_X_train, Y_train, batch_size=256),\n",
    "                    steps_per_epoch=len(V_X_train) // 256,\n",
    "                    epochs=20,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model.evaluate (V_X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
